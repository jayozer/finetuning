{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d568c49-3f18-43ed-83c3-08ab36c2e5f0",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To complete the following guide you will need to install the following packages:\n",
    "- fireworks-ai\n",
    "- numpy\n",
    "- pandas\n",
    "- pronouncing\n",
    "- requests\n",
    "- sentence-transformers\n",
    "- transformers\n",
    "\n",
    "You will also need:\n",
    "\n",
    "- Fireworks account (https://fireworks.ai/)\n",
    "- Fireworks API key\n",
    "- The firectl command-line interface (https://docs.fireworks.ai/tools-sdks/firectl/firectl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acdd56c2-87a7-419b-8c83-d65ee7e752dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acrobat/.local/share/virtualenvs/fine-tuning-workshop-WXOdYiJS/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/acrobat/.local/share/virtualenvs/fine-tuning-workshop-WXOdYiJS/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from fireworks.client import Fireworks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pronouncing\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "embeddings_model = SentenceTransformer('Alibaba-NLP/gte-base-en-v1.5', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c8be34-8480-4aba-a6a2-6d58a374e2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in as: jayozer@gmail.com\n",
      "Account ID: jayozer-ce1cd6\n"
     ]
    }
   ],
   "source": [
    "# Sign-in to your Fireworks account\n",
    "!firectl signin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85cbf23-f79c-4f87-87e0-aff1ba92607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variable\n",
    "api_key = os.getenv('FIREWORKS_API_KEY')\n",
    "\n",
    "client = Fireworks(api_key=api_key)\n",
    "\n",
    "# Replace the line below with your Fireworks account id\n",
    "account_id = os.getenv('FIREWORKS_ACCOUNT_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2450281-21b6-47aa-8cea-20acfa6401bf",
   "metadata": {},
   "source": [
    "## Problem Definition: Poem Generation\n",
    "\n",
    "*Note: The poem topics used in this example were synthetically generated by Claude 3 Opus*\n",
    "\n",
    "LLMs are capable of performing creative writing tasks. However, assessing the quality of such tasks, like poetry generation, is highly subjective.\n",
    "\n",
    "### Task\n",
    "In last week's notebook, we created a framework to quantitatively evaluate LLM-generated poetry. This week, you'll observe how to further improve this solution.\n",
    "\n",
    "As I am not a professional poet, I am unable to write high-level poetry myself. The ideal approach would be to search the web for high-quality poems that matches the style I want the LLM to generate. However, this method is very time-consuming. A more efficient approach is to use the \"critique and revise\" method, where the LLM first generates critiques on how each poem can be improved. We then ask the LLM to rewrite the poems based on these critiques. Finally, we fine-tune the LLM on the revised poems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d95223-0a67-4360-aa31-de6519545ee9",
   "metadata": {},
   "source": [
    "### Data\n",
    "The data can be found in the week-4 data folder.\n",
    "\n",
    "We will use the following datasets:\n",
    "- `./data/training_poem_topics.csv`\n",
    "- `./data/test_poem_topics.csv`\n",
    "\n",
    "Each of those datasets consists of 100 unique poem topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca29b5b2-f1fa-499d-95a2-c2042823c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('/Users/acrobat/Documents/GitHub/fine-tuning-workshop/src/week-4/data/training_poem_topics.csv')\n",
    "test_data = pd.read_csv('/Users/acrobat/Documents/GitHub/fine-tuning-workshop/src/week-4/data/test_poem_topics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8ab54-43cf-4b4e-9964-63f4b40f0413",
   "metadata": {},
   "source": [
    "### Foundation Model Baseline\n",
    "Our first step is to generate a poem for each of the topics in the training data using a foundation_model. We will then use the critique and revise method to improve upon these poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee8f3b7-69ad-46aa-8e5d-1392008d7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a csv file with a list of topics, generates a poem for each topic\n",
    "system_message = 'You are a professional poet. Write a unique and original contemporary poem about the topic suggested by the user. Your response should contain ONLY the content of the poem.'\n",
    "def generate_poems(model, df):\n",
    "    responses = list()\n",
    "    for i, row in enumerate(df.iterrows()):\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "              {\"role\": \"system\", \"content\": system_message},\n",
    "              {\"role\": \"user\", \"content\": row[1]['topic']}\n",
    "            ],\n",
    "        )\n",
    "        response = response.choices[0].message.content\n",
    "        responses.append(response)    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20470295-d4b7-4086-bee5-c5f190cfe855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first generate poems for poetry topics in our training set\n",
    "llama_70b_training_poems = generate_poems('accounts/fireworks/models/llama-v3p1-70b-instruct', training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf2abe-9ae7-4270-8f8f-ad114251a409",
   "metadata": {},
   "source": [
    "### Critique\n",
    "In the critique step, we create a scoring rubric and ask an LLM to generate improvements to the previously created poems based on the rubric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cabe42c-9ade-430e-a819-c726884e3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now use our scoring rubric to generate a list of critiques about each poem\n",
    "poem_guidelines = \"\"\"- Is the poem original?\n",
    "- Does the poem contain beauty, power, education or entertainment?\n",
    "- is the message of the poem clear? Is it a good message, or is it of little value to anyone?\n",
    "- Is the poem clear in its expression? Does it maintain coherence throughout?\n",
    "- If the poem is written in rhyming verse, then it should be rated according to how well the rhymes fit, not only with each other, but with the flow and the intended nuance of meaning the verse demands.\n",
    "- What form does the poem take? Is it a sonnet, free verse, haiku, etc.? How does the form contribute to the poem's impact?\n",
    "- Does the poet us the best possible choice of words in the poem? A person can ball, cry, sob, whimper, and shed tears, but which term would best fit the mood the poet is trying to convey?\"\"\"\n",
    "\n",
    "poem_crtique_rubric = f'''You are professional poet responsible for assessing the quality of AI generated poems.\n",
    "\n",
    "Assessment Guidelines:\n",
    "{poem_guidelines}\n",
    "\n",
    "Given the above guidelines, provide a list of ways that the poem could be improved.'''\n",
    "\n",
    "def critique_poems(poems, evaluation_model):\n",
    "    critiques = list()\n",
    "    for poem in poems:\n",
    "        response = client.chat.completions.create(\n",
    "            model=evaluation_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": poem_crtique_rubric},\n",
    "                {\"role\": \"user\", \"content\": poem}\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        try: \n",
    "            response = response.choices[0].message.content\n",
    "            critiques.append(response)\n",
    "        except json.JSONDecodeError as jde:\n",
    "            continue\n",
    "\n",
    "    return critiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9704887f-721c-4024-b256-8e0ef324a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_70b_training_critiques = critique_poems(llama_70b_training_poems, 'accounts/fireworks/models/llama-v3p1-70b-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec4cf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What a beautiful and imaginative poem! Based on the assessment guidelines, here are some suggestions for improvement:\\n\\n1. **Originality**: While the poem explores a unique and fascinating concept, some of the language and imagery may feel a bit familiar (e.g., \"skies of sapphire and amethyst,\" \"cities floated,\" \"trees like sentinels of silver and gold\"). Consider adding more distinct and unexpected elements to make the poem truly stand out.\\n2. **Clarity and coherence**: The poem\\'s structure and language are generally clear, but some stanzas feel a bit disconnected from each other. For example, the transition from the third stanza to the fourth feels a bit abrupt. Consider revising the poem to create a more cohesive narrative flow.\\n3. **Message and value**: The poem\\'s message is largely one of nostalgia and longing for a lost world. While this is a powerful and relatable theme, it may benefit from a clearer sense of purpose or resolution. Consider adding more depth or nuance to the poem\\'s exploration of this theme.\\n4. **Rhyme and meter**: The poem\\'s rhyme scheme is generally well-executed, but some of the rhymes feel a bit forced or convenient (e.g., \"ease\" and \"please\" in the third stanza). Consider revising the poem to create a more natural and organic rhyme scheme.\\n5. **Word choice**: While the poem\\'s language is generally rich and evocative, some words feel a bit overused or clichéd (e.g., \"whispered promise,\" \"mystical shore\"). Consider revising the poem to incorporate more precise and unexpected word choices.\\n6. **Form**: The poem\\'s form is largely free verse, which suits the dreamlike and imaginative nature of the content. However, consider experimenting with more structured forms (e.g., sonnets, villanelles) to create a more dynamic and varied poetic landscape.\\n7. **Specificity and detail**: While the poem\\'s imagery is often vivid and engaging, some of the descriptions feel a bit generic or vague (e.g., \"cities floated,\" \"creatures of this land\"). Consider adding more specific and detailed descriptions to bring the poem\\'s world to life.\\n\\nSome specific suggestions for revision:\\n\\n* Consider adding more sensory details to help the reader experience the world of the poem. For example, what does the air smell like in this mystical realm? What kind of sounds do the creatures make?\\n* Revise the fourth stanza to create a more cohesive and logical connection to the rest of the poem. Perhaps the speaker could reflect on the nature of memory and how it relates to their longing for this lost world.\\n* Experiment with more varied and unexpected language to describe the poem\\'s central themes and images. For example, instead of using the phrase \"heart in vain,\" consider something like \"a hollowed-out ache\" or \"a longing that refuses to settle.\"\\n* Consider adding more tension or conflict to the poem to create a sense of drama or urgency. For example, what are the consequences of the speaker\\'s inability to return to this mystical realm? How does this longing affect their daily life?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_70b_training_critiques[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9eff6b-4702-4968-83ba-95581c0721af",
   "metadata": {},
   "source": [
    "### Revise\n",
    "In the revise step, we create a new prompt that tells the LLM to generate a revised poem, given the previously generated critiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9faf4fa-3784-4966-bf96-02d970fb223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now give the LLM both the poem and the critiques, and tell it to improve the poem based on the following critiques.\n",
    "improvement_sys_message = '''You are a professional poet. Improve the poem, given the following critiques.\n",
    "\n",
    "Your response must ONLY contain the content of the improved poem. DO NOT TELL ME YOUR CHANGES, JUST GIVE ME THE REVISED POEM!'''\n",
    "\n",
    "def generate_improved_poems(model, poems, critiques):\n",
    "    responses = list()\n",
    "    for i, poem in enumerate(poems):\n",
    "\n",
    "        user_message = f''''\n",
    "poem:      \n",
    "{poem}\n",
    "\n",
    "critiques:\n",
    "{critiques[i]}'''\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "              {\"role\": \"system\", \"content\": improvement_sys_message},\n",
    "              {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "        )\n",
    "        response = response.choices[0].message.content\n",
    "        responses.append(response)    \n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e109d8f-6764-465e-802d-e2f224fd4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_70b_training_improved_poems = generate_improved_poems('accounts/fireworks/models/llama-v3p1-70b-instruct', llama_70b_training_poems, llama_70b_training_critiques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d76495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the hollow of my mind, a creaking door\n",
      "A murmured vow of a world beyond the astral shore\n",
      "A dimension shrouded, yet echoes seep\n",
      "A yearning to return, a hollowed-out ache\n",
      "\n",
      "I recall the firmament of cerulean and heliotrope\n",
      "Where cities drifted, and rivers flowed in auroral mist\n",
      "The trees, like silvan guardians of silver and orichalc\n",
      "Their leaves, a susurrus of cryptic whispers, a language unspun\n",
      "\n",
      "In this forgotten realm, I wandered, unmoored\n",
      "A stranger in a world of wonder, where the impossible roamed\n",
      "The creatures of this land, a cacophony of forms\n",
      "Dancing on the solar wind, a kaleidoscope of chromatic norms\n",
      "\n",
      "The memories, a palimpsest of fractured time\n",
      "A puzzle I've tried to reassemble, in the syntax of the mind\n",
      "But like the shards of a shattered prism's refracted light\n",
      "Reflections distorted, a reality unseen, yet felt in the night\n",
      "\n",
      "In dreams, I still revisit this mystic littoral\n",
      "Where the moon dipped in the ocean, and the sun rose, a burning coal\n",
      "But when I wake, the recollections dissipate\n",
      "Leaving me with only the ache of a memory delayed, a longing that refuses to settle\n",
      "\n",
      "Yet, in the silence, I still hear the summons\n",
      "A whispered call, a melody of longing and desire\n",
      "To reclaim the memories of a forgotten dimension's fire\n",
      "To relive the wonder, and the heartache that aspires\n",
      "\n",
      "In the hollow of my mind, the door creaks open wide\n",
      "A threshold beckons, to the world beyond the astral tide\n",
      "And I am drawn, a moth to the flame, a heart to the fire\n",
      "A longing to return, to the world that I desire.\n"
     ]
    }
   ],
   "source": [
    "print(llama_70b_training_improved_poems[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6616c-6b12-4076-9085-a81066d5f3ee",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n",
    "We know fine-tune a smaller LLM using the revised poems. This is similar to the knowledge distillation method from last week's notebook, except we are fine-tuning on the revised poems of the larger model, rather than the original poems that it generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9cb57c-8342-43dd-be96-8c0cfe233e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the improved poems to fireworks as our fine-tuning dataset\n",
    "def format_poem_for_fireworks(topic, poem):\n",
    "    return {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": system_message}, \n",
    "        {\"role\": \"user\", \"content\": topic}, \n",
    "        {\"role\": \"assistant\", \"content\": poem}\n",
    "    ]}\n",
    "\n",
    "topics = training_data['topic'].tolist()\n",
    "json_objs = list()\n",
    "for i, poem in enumerate(llama_70b_training_improved_poems):\n",
    "    msg = {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": system_message}, \n",
    "        {\"role\": \"user\", \"content\": topics[i]}, \n",
    "        {\"role\": \"assistant\", \"content\": poem}\n",
    "    ]}    \n",
    "    json_objs.append(msg)\n",
    "\n",
    "dataset_file_name = 'poem_training_data.jsonl'\n",
    "dataset_id = 'improved-poem-data-v1'\n",
    "with open(dataset_file_name, 'w') as f:\n",
    "    for obj in json_objs:\n",
    "        json.dump(obj, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "532ba7c4-d8a3-44fd-99da-013410862a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178.55 KiB / 178.55 KiB [---------------------------] 100.00% 5.13 MiB p/s 200ms\n"
     ]
    }
   ],
   "source": [
    "# Upload our dataset to fireworks\n",
    "!firectl create dataset {dataset_id} {dataset_file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd63bb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/acrobat/Documents/GitHub/fine-tuning-workshop/src/week-4\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "759f5765-bbc1-419d-b822-ebed16fb28da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accounts/jayozer-ce1cd6/fineTuningJobs/b203ef3333a04c1d95cd37e7ab695b71\n",
      "Display Name: improved-poems-v1\n",
      "Create Time: 2024-09-25 14:49:32\n",
      "State: CREATING\n",
      "Dataset: accounts/jayozer-ce1cd6/datasets/improved-poem-data-v1\n",
      "Status: OK\n",
      "Created By: jayozer@gmail.com\n",
      "Conversation:\n",
      "  Jinja Template: \n",
      "{%- set _mode = mode | default('generate', true) -%}\n",
      "{%- set stop_token = '<|eot_id|>' -%}\n",
      "{%- set message_roles = ['SYSTEM', 'USER', 'ASSISTANT'] -%}\n",
      "{%- set ns = namespace(initial_system_message_handled=false, last_assistant_index_for_eos=-1, messages=messages) -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if not message.get('role') -%}\n",
      "        {{ raise_exception('Key [role] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if message['role'] | upper not in message_roles -%}\n",
      "        {{ raise_exception('Invalid role ' + message['role']|tojson + '. Only ' + message_roles|tojson + ' are supported.') }}\n",
      "    {%- endif -%}\n",
      "    {%- if 'content' not in message -%}\n",
      "        {{ raise_exception('Key [content] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if loop.last and message['role'] | upper == 'ASSISTANT' -%}\n",
      "        {%- set ns.last_assistant_index_for_eos = loop.index0 -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' -%}\n",
      "    {{ bos_token }}\n",
      "{%- endif -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if message['role'] | upper == 'SYSTEM' and not ns.initial_system_message_handled -%}\n",
      "        {%- set ns.initial_system_message_handled = true -%}\n",
      "        {{ '<|start_header_id|>system<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "    {%- elif message['role'] | upper != 'SYSTEM' -%}\n",
      "        {%- if (message['role'] | upper == 'USER') != ((loop.index0 - (1 if ns.initial_system_message_handled else 0)) % 2 == 0) -%}\n",
      "            {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\n",
      "        {%- endif -%}\n",
      "        {%- if message['role'] | upper == 'USER' -%}\n",
      "            {{ '<|start_header_id|>user<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "        {%- elif message['role'] | upper == 'ASSISTANT' -%}\n",
      "            {%- if _mode == 'train' -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + unk_token + message['content'] + stop_token + unk_token }}\n",
      "            {%- else -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + message['content'] + (stop_token if loop.index0 != ns.last_assistant_index_for_eos else '') }}\n",
      "            {%- endif -%}\n",
      "        {%- endif -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' and ns.last_assistant_index_for_eos == -1 -%}\n",
      "    {{ '<|start_header_id|>assistant<|end_header_id|>' }}\n",
      "{%- endif -%}\n",
      "\n",
      "Base Model: accounts/fireworks/models/llama-v3p1-70b-instruct\n",
      "Epochs: 2\n",
      "Learning Rate: 0.0002\n",
      "Lora Rank: 32\n",
      "Batch Size: 4\n",
      "Evaluation Split: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a fine-tuning job\n",
    "!firectl create fine-tuning-job --settings-file poem_generation_fine_tuning_config.yaml --display-name improved-poems-v1 --dataset {dataset_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f544dafc-10a8-4f2a-92af-9e0f13e20b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT THIS ID WILL CHANGE WHEN YOU RUN THE FINE-TUNING JOB ON YOUR ACCOUNT!!!\n",
    "# The model id is printed in the stdout of the cell above as Name: accounts/{account_id}/fineTuningJobs/{ft_model_id}\n",
    "ft_model_id = 'b203ef3333a04c1d95cd37e7ab695b71' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39db4642-5075-4e80-915d-d9b0d96ba297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accounts/jayozer-ce1cd6/fineTuningJobs/b203ef3333a04c1d95cd37e7ab695b71\n",
      "Display Name: improved-poems-v1\n",
      "Create Time: 2024-09-25 14:49:32\n",
      "State: RUNNING\n",
      "Dataset: accounts/jayozer-ce1cd6/datasets/improved-poem-data-v1\n",
      "Status: OK\n",
      "Created By: jayozer@gmail.com\n",
      "Conversation:\n",
      "  Jinja Template: \n",
      "{%- set _mode = mode | default('generate', true) -%}\n",
      "{%- set stop_token = '<|eot_id|>' -%}\n",
      "{%- set message_roles = ['SYSTEM', 'USER', 'ASSISTANT'] -%}\n",
      "{%- set ns = namespace(initial_system_message_handled=false, last_assistant_index_for_eos=-1, messages=messages) -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if not message.get('role') -%}\n",
      "        {{ raise_exception('Key [role] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if message['role'] | upper not in message_roles -%}\n",
      "        {{ raise_exception('Invalid role ' + message['role']|tojson + '. Only ' + message_roles|tojson + ' are supported.') }}\n",
      "    {%- endif -%}\n",
      "    {%- if 'content' not in message -%}\n",
      "        {{ raise_exception('Key [content] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if loop.last and message['role'] | upper == 'ASSISTANT' -%}\n",
      "        {%- set ns.last_assistant_index_for_eos = loop.index0 -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' -%}\n",
      "    {{ bos_token }}\n",
      "{%- endif -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if message['role'] | upper == 'SYSTEM' and not ns.initial_system_message_handled -%}\n",
      "        {%- set ns.initial_system_message_handled = true -%}\n",
      "        {{ '<|start_header_id|>system<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "    {%- elif message['role'] | upper != 'SYSTEM' -%}\n",
      "        {%- if (message['role'] | upper == 'USER') != ((loop.index0 - (1 if ns.initial_system_message_handled else 0)) % 2 == 0) -%}\n",
      "            {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\n",
      "        {%- endif -%}\n",
      "        {%- if message['role'] | upper == 'USER' -%}\n",
      "            {{ '<|start_header_id|>user<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "        {%- elif message['role'] | upper == 'ASSISTANT' -%}\n",
      "            {%- if _mode == 'train' -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + unk_token + message['content'] + stop_token + unk_token }}\n",
      "            {%- else -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + message['content'] + (stop_token if loop.index0 != ns.last_assistant_index_for_eos else '') }}\n",
      "            {%- endif -%}\n",
      "        {%- endif -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' and ns.last_assistant_index_for_eos == -1 -%}\n",
      "    {{ '<|start_header_id|>assistant<|end_header_id|>' }}\n",
      "{%- endif -%}\n",
      "\n",
      "Base Model: accounts/fireworks/models/llama-v3p1-70b-instruct\n",
      "Epochs: 2\n",
      "Learning Rate: 0.0002\n",
      "Lora Rank: 32\n",
      "Batch Size: 4\n",
      "Evaluation Split: 0\n"
     ]
    }
   ],
   "source": [
    "# Wait until the State of the fine-tuning job is listed as COMPLETED (~10-20 minutes)\n",
    "!firectl get fine-tuning-job {ft_model_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33bf50b-0a15-4361-acb8-38a427dfd1fc",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Finally, we evaluate the fine-tuned model on our test data. In the previous weeks notebook, the knowledge distillation method resulted in an average LLM judge score of 8.21. We expect to receive a higher score now that we are fine-tuning on the revised poems rather than the initial poems that the large model generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08b52e9f-8948-42d0-9d07-7d5d8515311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the fine-tuned model\n",
    "!firectl deploy {ft_model_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22d352a5-5693-4b1f-b43f-b08321c1de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accounts/jayozer-ce1cd6/models/b203ef3333a04c1d95cd37e7ab695b71\n",
      "Create Time: 2024-09-25 15:12:55\n",
      "State: READY\n",
      "Status: OK\n",
      "Kind: HF_PEFT_ADDON\n",
      "Base Model Details:\n",
      "  Checkpoint Format: CHECKPOINT_FORMAT_UNSPECIFIED\n",
      "Peft Details:\n",
      "  Base Model: accounts/fireworks/models/llama-v3p1-70b-instruct\n",
      "  R: 32\n",
      "  Target Modules: [v_proj, k_proj, q_proj, gate_proj, o_proj, down_proj, up_proj]\n",
      "Conversation Config:\n",
      "  Style: jinja\n",
      "Context Length: 131072\n",
      "Fine Tuning Job: accounts/jayozer-ce1cd6/fineTuningJobs/b203ef3333a04c1d95cd37e7ab695b71\n",
      "Deployed Model Refs: \n",
      "  [{\n",
      "    Name: accounts/jayozer-ce1cd6/deployedModels/b203ef3333a04c1d95cd37e7ab695b71-68342157\n",
      "    Deployment: accounts/fireworks/deployments/5bb3209d\n",
      "    State: DEPLOYED\n",
      "    Default: true\n",
      "  }]\n"
     ]
    }
   ],
   "source": [
    "# Wait until the the Deploymed Model Refs lists the state of the model as \"DEPLOYED\" (~5-20 minutes).\n",
    "!firectl get model {ft_model_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cdea9fb-78cc-4293-ac5a-6f5597327d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate poems on the test set using our fine-tuned model\n",
    "ft_poems = generate_poems(f'accounts/{account_id}/models/{ft_model_id}', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0297ba4-6533-4763-a12f-2579a9665200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate poems based on their average length (# of characters)\n",
    "def calculate_avg_length(poems):\n",
    "    return int(np.mean([len(poem) for poem in poems]))\n",
    "\n",
    "# Evaluate poems based on the pct of stanzas that contain a rhyme\n",
    "def calculate_rhyming_fct(poem):\n",
    "    stanzas = poem.split('\\n\\n')\n",
    "    stanzas = [stanza for stanza in stanzas if len(stanza.split('\\n')) >= 1]\n",
    "    \n",
    "    num_rhyming_stanzas = 0\n",
    "    for stanza in stanzas:\n",
    "        lines = stanza.split('\\n')\n",
    "        end_words = [line.split(' ')[-1].strip('.?!\"\\',') for line in lines]\n",
    "        found_rhyme = False\n",
    "        for i in range(len(end_words)):\n",
    "            for j in range(i + 1, len(end_words)):\n",
    "                found_rhyme = True if found_rhyme or (end_words[j] in pronouncing.rhymes(end_words[i])) else False\n",
    "                \n",
    "        if found_rhyme:\n",
    "            num_rhyming_stanzas += 1\n",
    "\n",
    "    if not len(stanzas):\n",
    "        print(poem)\n",
    "    return num_rhyming_stanzas / len(stanzas)\n",
    "\n",
    "# Evaluate poems based on how often they have a positive sentiment\n",
    "def has_positive_sentiment(poem):\n",
    "    try:\n",
    "        sentiment = sentiment_pipeline(poem)[0]\n",
    "        return True if sentiment['label'] == 'POSITIVE' else False\n",
    "    except:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9cbb3fd-1bf0-4321-b511-fbc9e6bbf0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic Evaluation\n",
      "Average Length: 1255\n",
      "Rhyming Pct: 73%\n",
      "Positive Sentiment: 92%\n"
     ]
    }
   ],
   "source": [
    "# Calculate heuristics of our fine-tuned poems\n",
    "print(\"Heuristic Evaluation\")\n",
    "print(f'Average Length: {calculate_avg_length(ft_poems)}')\n",
    "print(f\"Rhyming Pct: {int(100 * np.mean([calculate_rhyming_fct(poem) for poem in ft_poems]))}%\")\n",
    "print(f\"Positive Sentiment: {int(100 * np.mean([has_positive_sentiment(poem) for poem in ft_poems]))}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87c40a26-72af-436b-a186-659879895d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate poems using the LLM as a Judge strategy\n",
    "poem_evaluation_rubric = f'''You are professional poet responsible for assessing the quality of AI generated poems.\n",
    "\n",
    "Score each poem on a scale of 0 to 10, where 10 represents the best possible poem.\n",
    "\n",
    "Scoring Guidelines:\n",
    "{poem_guidelines}\n",
    "\n",
    "Think through your reasoning step-by-step and explain your reasoning. Steps for judging a poem:\n",
    "1. Read the Poem Multiple Times: Read it aloud and silently to capture both the meaning and the sound.\n",
    "2. Take Notes: Jot down initial impressions, notable phrases, and any questions that arise.\n",
    "3. Analyze the Elements: Break down the poem into its components (content, structure, language, sound).\n",
    "4. Reflect on Your Experience: Consider your emotional response and personal connection to the poem.\n",
    "\n",
    "The last line in your response MUST be a json object {{\"score\": XXX}}, where XXX is the score you are giving the response.'''\n",
    "\n",
    "def evaluate_poems(poems, evaluation_model):\n",
    "    scores = list()\n",
    "    for poem in poems:\n",
    "        response = client.chat.completions.create(\n",
    "            model=evaluation_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": poem_evaluation_rubric},\n",
    "                {\"role\": \"user\", \"content\": poem}\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        try: \n",
    "            response = response.choices[0].message.content\n",
    "            score = int(json.loads(response.split('\\n')[-1])['score'])  \n",
    "            scores.append(score)\n",
    "        except json.JSONDecodeError as jde:\n",
    "            continue\n",
    "        \n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd47aa0d-6d32-4d51-83e8-ba7a77b39694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg LLM Judge Score: 8.32\n"
     ]
    }
   ],
   "source": [
    "# Use the LLM to evaluate our fine-tuned model\n",
    "ft_avg_score = evaluate_poems(ft_poems, 'accounts/fireworks/models/llama-v3p1-70b-instruct')\n",
    "print(f\"Avg LLM Judge Score: {round(ft_avg_score , 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c4f7d0b-050c-4812-b07a-cbcadd6007c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undeploy the fine-tuned model (does not cost anything extra, but Fireworks may limit your number of deployed models).\n",
    "!firectl undeploy {ft_model_id}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
