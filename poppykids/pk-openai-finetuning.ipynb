{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc99643-ee3c-47a8-8d66-776f1439574f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To complete the following guide you will need to install the following packages:\n",
    "\n",
    "- openai\n",
    "- pandas\n",
    "- requests\n",
    "\n",
    "You will also need:\n",
    "\n",
    "- OpenAI account (https://platform.openai.com/)\n",
    "- OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37325ced-0bac-4114-ac6f-7675750be022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/Users/scottkramer/.pyenv/versions/3.9.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#! pipenv install openai pandas requests python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04f5690-a826-4f0f-9fb3-d69f1208a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f0d69d-f8f0-4bb6-bca4-13da071e32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variable\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0966717",
   "metadata": {},
   "source": [
    "# Create the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f39af4-94fc-4603-90c8-3646ff451edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "input_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/clean_faq_dataset.txt'\n",
    "train_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/train.tsv'\n",
    "test_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/test.tsv'\n",
    "\n",
    "def read_qa_pairs(file_path):\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        current_question = None\n",
    "        current_answer = None\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('Question:'):\n",
    "                if current_question and current_answer:\n",
    "                    qa_pairs.append((current_question, current_answer))\n",
    "                current_question = line[9:].strip()\n",
    "                current_answer = None\n",
    "            elif line.startswith('Answer:'):\n",
    "                current_answer = line[7:].strip()\n",
    "        if current_question and current_answer:\n",
    "            qa_pairs.append((current_question, current_answer))\n",
    "    return qa_pairs\n",
    "\n",
    "def write_tsv(file_path, data):\n",
    "    with open(file_path, 'w', encoding='utf-8', newline='') as file:\n",
    "        file.write('question\\tanswer\\n')  # Header\n",
    "        for question, answer in data:\n",
    "            file.write(f'{question}\\t{answer}\\n')\n",
    "\n",
    "# Read Q&A pairs\n",
    "qa_pairs = read_qa_pairs(input_file)\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(qa_pairs)\n",
    "\n",
    "# Calculate split index\n",
    "split_index = int(len(qa_pairs) * 0.8)\n",
    "\n",
    "# Split the data\n",
    "train_data = qa_pairs[:split_index]\n",
    "test_data = qa_pairs[split_index:]\n",
    "\n",
    "# Write train and test data\n",
    "write_tsv(train_file, train_data)\n",
    "write_tsv(test_file, test_data)\n",
    "\n",
    "print(f\"Train data ({len(train_data)} pairs) written to {train_file}\")\n",
    "print(f\"Test data ({len(test_data)} pairs) written to {test_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d1335",
   "metadata": {},
   "source": [
    "### finetuning training dataset curation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ea02f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted data has been written to /Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq_training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "input_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/train.tsv'\n",
    "output_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq_training_data.jsonl'\n",
    "\n",
    "def process_qa_pair(question, answer):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are Poppy, a helpful assistant for Poppy Kids Pediatric Dentistry.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Read TSV and write JSONL\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    next(reader)  # Skip header row\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) == 2:\n",
    "            question, answer = row\n",
    "            formatted_data = process_qa_pair(question, answer)\n",
    "            json.dump(formatted_data, outfile, ensure_ascii=False)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "print(f\"Formatted data has been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a609ba1",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "input_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/test.tsv'\n",
    "output_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq_test_data.jsonl'\n",
    "\n",
    "def process_qa_pair(question, answer):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are Poppy, a helpful assistant for Poppy Kids Pediatric Dentistry.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Read TSV and write JSONL\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    next(reader)  # Skip header row\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) == 2:\n",
    "            question, answer = row\n",
    "            formatted_data = process_qa_pair(question, answer)\n",
    "            json.dump(formatted_data, outfile, ensure_ascii=False)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "print(f\"Formatted data has been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229e9f8",
   "metadata": {},
   "source": [
    "# Finetuning Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7800f8-75b2-4fcd-b755-5db04f601ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully. File ID: file-RW2yeYnEXOdcNWavMaHYY0b2\n"
     ]
    }
   ],
   "source": [
    "# Uploads training data to OpenAI\n",
    "# Define the path for the training data file\n",
    "dataset_file_name = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq_training_data.jsonl'\n",
    "\n",
    "# Read the existing JSONL file\n",
    "with open(dataset_file_name, 'r') as f:\n",
    "    training_json = [json.loads(line) for line in f]\n",
    "\n",
    "# Upload the file to OpenAI\n",
    "file_upload = client.files.create(\n",
    "    file=open(dataset_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(f\"File uploaded successfully. File ID: {file_upload.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796eb433-8370-494a-82ce-df3054c0de87",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n",
    "\n",
    "We will now fine-tune models using the OpenAI API. OpenAI supports creating fine-tuning jobs both via the fine-tuning UI or programmatically. The number of epochs, learning rate, and batch size can all be optimized manually for your use case. In this exercise, we will use the default parameters.\n",
    "\n",
    "See https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0186ffee-554b-4587-a279-f9743a952859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-Hg6Gfoq45O3M4EeNdq93rvHM', created_at=1726617261, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-txV60G5rl5rp8sFMUYSZwoAv', result_files=[], seed=1798807987, status='validating_files', trained_tokens=None, training_file='file-RW2yeYnEXOdcNWavMaHYY0b2', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a training job with the default hyperparameters\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file='file-RW2yeYnEXOdcNWavMaHYY0b2', # the file ID that was returned when the training file was uploaded to the OpenAI API.\n",
    "  model='gpt-4o-mini-2024-07-18' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28011a3b",
   "metadata": {},
   "source": [
    "# List current jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed31bb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Hg6Gfoq45O3M4EeNdq93rvHM', created_at=1726617261, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-txV60G5rl5rp8sFMUYSZwoAv', result_files=[], seed=1798807987, status='running', trained_tokens=None, training_file='file-RW2yeYnEXOdcNWavMaHYY0b2', validation_file=None, estimated_finish=1726620027, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "#client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "print(client.fine_tuning.jobs.retrieve(\"ftjob-Hg6Gfoq45O3M4EeNdq93rvHM\"))\n",
    "\n",
    "# Cancel a job\n",
    "#client.fine_tuning.jobs.cancel(\"ftjob-abc123\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "#client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-abc123\", limit=10)\n",
    "\n",
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "#client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d208e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"To brush your child's teeth, use a small, soft-bristled toothbrush with a pea-sized amount of fluoride toothpaste. Brush gently in circular motions for two minutes, covering all surfaces of the teeth. Use a child-friendly method to ensure thorough and pleasant brushing.\", refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:acrobat::A8d1zaGt\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you provide me with instructions on how to brush my child's teeth?\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa875c-d603-4afd-a869-efaf1b1fcbe5",
   "metadata": {},
   "source": [
    "### Evaluate Results - Really not possible by inferring, I can do semantic check to see or human evaluation. \n",
    "\n",
    "We will now deploy our models and evaluate the results. We will calculate the accuracy on two different models.\n",
    "\n",
    "- The base model gpt-4o-mini model without any fine-tuning.\n",
    "- Our fine-tuned model.\n",
    "\n",
    "In the example below, you'll see that fine-tuning improved accuracy on our test set from 69% to 94%!\n",
    "\n",
    "See https://platform.openai.com/docs/guides/fine-tuning/use-a-fine-tuned-model for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb467405",
   "metadata": {},
   "source": [
    "Below does not make sense for this use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad57cc5-d98c-43c5-a7d4-0567136a5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses an LLM to predicted class labels for a list of support tickets\n",
    "def classify_tickets(tickets, model):\n",
    "    responses = list()\n",
    "\n",
    "    for ticket in tickets:\n",
    "        user_prompt = create_prompt(ticket)\n",
    "    \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{ \"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0, # setting temperature to 0 for this use case, so that responses are as deterministic as possible\n",
    "            stop=[\"</category>\"],\n",
    "            max_tokens=2048,\n",
    "        )\n",
    "\n",
    "        response = response.choices[0].message.content.split(\"<category>\")[-1].strip()\n",
    "        responses.append(response)\n",
    "\n",
    "    return responses\n",
    "\n",
    "\n",
    "# Calculates the percent of predictions we classified correctly\n",
    "def evaluate_accuracy(predicted, actual):\n",
    "    num_correct = sum([predicted[i] == actual[i] for i in range(len(actual))])\n",
    "    return round(100 * num_correct / len(actual), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e68e93-61f2-465d-8596-c32cdb896d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 70.59%\n",
      "Test Set Accuracy: 67.65%\n"
     ]
    }
   ],
   "source": [
    "# Determine how the base model without any fine-tuning performs\n",
    "model_id = 'gpt-4o-mini'\n",
    "\n",
    "training_responses = classify_tickets(\n",
    "    tickets=training_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "accuracy = evaluate_accuracy(training_responses, training_labels)\n",
    "print(f\"Training Set Accuracy: {accuracy}%\")\n",
    "\n",
    "test_responses = classify_tickets(\n",
    "    tickets=test_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "\n",
    "accuracy = evaluate_accuracy(test_responses, test_labels)\n",
    "print(f\"Test Set Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "556cc993-59ec-4f89-b33e-8bcd2d7d383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 100.0%\n",
      "Test Set Accuracy: 95.59%\n"
     ]
    }
   ],
   "source": [
    "# Determine how the base model performs with the increases rank, epochs, and learning rate\n",
    "#model_id = 'ft:gpt-4o-mini-2024-07-18:brainiac-labs::A1b3dY1n' # REPLACE THIS WITH THE OUTPUT MODEL ID IN THE OPENAI FINE-TUNING DASHBOARD\n",
    "load_dotenv()\n",
    "model_id = os.getenv('MODEL_ID_ONE')\n",
    "\n",
    "training_responses = classify_tickets(\n",
    "    tickets=training_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "accuracy = evaluate_accuracy(training_responses, training_labels)\n",
    "print(f\"Training Set Accuracy: {accuracy}%\")\n",
    "\n",
    "test_responses = classify_tickets(\n",
    "    tickets=test_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "\n",
    "accuracy = evaluate_accuracy(test_responses, test_labels)\n",
    "print(f\"Test Set Accuracy: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
