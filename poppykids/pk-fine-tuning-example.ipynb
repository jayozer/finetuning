{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6785f47a-5670-45a9-80df-a4d6f47b1181",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To complete the following guide you will need to install the following packages:\n",
    "- fireworks-ai\n",
    "- pandas\n",
    "- requests\n",
    "\n",
    "You will also need:\n",
    "\n",
    "- Fireworks account (https://fireworks.ai/)\n",
    "- Fireworks API key\n",
    "- The firectl command-line interface (https://docs.fireworks.ai/tools-sdks/firectl/firectl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e869493a-09c8-4036-8573-12a1d33e8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pipenv install pandas requests fireworks-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56a030b-9e82-43cc-8cde-ab20da4280a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from fireworks.client import Fireworks\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b2526b-5718-4c9e-9e56-69314314d76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in as: jayozer@gmail.com\n",
      "Account ID: jayozer-ce1cd6\n"
     ]
    }
   ],
   "source": [
    "# Sign-in to your Fireworks account\n",
    "!firectl signin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbee1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in as: jayozer@gmail.com\n",
      "Account ID: jayozer-ce1cd6\n"
     ]
    }
   ],
   "source": [
    "!firectl whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5636ee-8032-4f24-b69a-c90414078d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have the FIREWORKS_API_KEY environment variable set to your account's key!\n",
    "# os.environ['FIREWORKS_API_KEY'] = 'XXX'\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variable\n",
    "api_key = os.getenv('FIREWORKS_API_KEY')\n",
    "\n",
    "client = Fireworks(api_key=api_key)\n",
    "\n",
    "# Replace the line below with your Fireworks account id\n",
    "account_id = os.getenv('FIREWORKS_ACCOUNT_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665b4ed-3a6d-4b22-a213-f286435eee1a",
   "metadata": {},
   "source": [
    "## Problem Definition: Pediatric dentistry corpus finetuning\n",
    "\n",
    "*Note: The problem definition, data, and labels used in this example were synthetically generated by Claude 3 Opus*\n",
    "\n",
    "Short Q&A answers for a pediatric dentistry chatbot. \n",
    "\n",
    "### Task\n",
    "Increase the accuracy of inference on the test.tsv dataset using finetuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da13a3-2659-4711-ab5e-2042895f2d45",
   "metadata": {},
   "source": [
    "#### Labeled Data\n",
    "\n",
    "We will use the following datasets:\n",
    "- `./pk_data/train.tsv`\n",
    "- `./pk_data/test.tsv`\n",
    "\n",
    "- Main q&A pair data set is in ./pk_data/clean_faq_dataset.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928062f6",
   "metadata": {},
   "source": [
    "# Create the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0da14f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data (675 pairs) written to /Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/train.tsv\n",
      "Test data (169 pairs) written to /Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/test.tsv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "input_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/clean_faq_dataset.txt'\n",
    "train_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/train.tsv'\n",
    "test_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/test.tsv'\n",
    "\n",
    "def read_qa_pairs(file_path):\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        current_question = None\n",
    "        current_answer = None\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('Question:'):\n",
    "                if current_question and current_answer:\n",
    "                    qa_pairs.append((current_question, current_answer))\n",
    "                current_question = line[9:].strip()\n",
    "                current_answer = None\n",
    "            elif line.startswith('Answer:'):\n",
    "                current_answer = line[7:].strip()\n",
    "        if current_question and current_answer:\n",
    "            qa_pairs.append((current_question, current_answer))\n",
    "    return qa_pairs\n",
    "\n",
    "def write_tsv(file_path, data):\n",
    "    with open(file_path, 'w', encoding='utf-8', newline='') as file:\n",
    "        file.write('question\\tanswer\\n')  # Header\n",
    "        for question, answer in data:\n",
    "            file.write(f'{question}\\t{answer}\\n')\n",
    "\n",
    "# Read Q&A pairs\n",
    "qa_pairs = read_qa_pairs(input_file)\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(qa_pairs)\n",
    "\n",
    "# Calculate split index\n",
    "split_index = int(len(qa_pairs) * 0.8)\n",
    "\n",
    "# Split the data\n",
    "train_data = qa_pairs[:split_index]\n",
    "test_data = qa_pairs[split_index:]\n",
    "\n",
    "# Write train and test data\n",
    "write_tsv(train_file, train_data)\n",
    "write_tsv(test_file, test_data)\n",
    "\n",
    "print(f\"Train data ({len(train_data)} pairs) written to {train_file}\")\n",
    "print(f\"Test data ({len(test_data)} pairs) written to {test_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810815db-a6b2-4d1c-bea8-f4975cbcc3b9",
   "metadata": {},
   "source": [
    "### finetuning training dataset curation\n",
    "\n",
    "We first must transform our dataset into the format expected by Fireworks, and then upload the dataset. The dataset must conform to the schema expected by the Chat Completions API.\n",
    "\n",
    "See https://docs.fireworks.ai/fine-tuning/fine-tuning-models#conversation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f8cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted data has been written to /Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq__training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "input_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/train.tsv'\n",
    "output_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq_training_data.jsonl'\n",
    "\n",
    "def process_qa_pair(question, answer):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are Poppy, a helpful assistant for Poppy Kids Pediatric Dentistry.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Read TSV and write JSONL\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    next(reader)  # Skip header row\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) == 2:\n",
    "            question, answer = row\n",
    "            formatted_data = process_qa_pair(question, answer)\n",
    "            json.dump(formatted_data, outfile, ensure_ascii=False)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "print(f\"Formatted data has been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee605d88",
   "metadata": {},
   "source": [
    "#test data curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bcb9fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted data has been written to /Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq_test_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "input_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/test.tsv'\n",
    "output_file = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq_test_data.jsonl'\n",
    "\n",
    "def process_qa_pair(question, answer):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are Poppy, a helpful assistant for Poppy Kids Pediatric Dentistry.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Read TSV and write JSONL\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    next(reader)  # Skip header row\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) == 2:\n",
    "            question, answer = row\n",
    "            formatted_data = process_qa_pair(question, answer)\n",
    "            json.dump(formatted_data, outfile, ensure_ascii=False)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "print(f\"Formatted data has been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68de340d-f246-4243-a205-5a4ebf2b7acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 675\n",
      "First example: {'messages': [{'role': 'system', 'content': 'You are Poppy, a helpful assistant for Poppy Kids Pediatric Dentistry.'}, {'role': 'user', 'content': 'Why are fillings necessary for baby teeth?'}, {'role': 'assistant', 'content': \"Fillings in baby teeth are necessary to treat cavities, prevent discomfort, pain, and further dental issues such as infections, and to ensure the overall health and functionality of a child's teeth.\"}]}\n"
     ]
    }
   ],
   "source": [
    "# Writes the data to a file so that it can be uploaded to Fireworks\n",
    "dataset_file_name = '/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk_faq_training_data.jsonl'\n",
    "dataset_id = 'pk-faq-v1'  # The dash vs underscore issue. Underscore does not work, must be dashes. \n",
    "\n",
    "# Read the existing file to verify its contents\n",
    "with open(dataset_file_name, 'r') as f:\n",
    "    training_json = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"Number of training examples: {len(training_json)}\")\n",
    "print(f\"First example: {training_json[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a68299-9751-4263-ae87-1a9a531caf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301.87 KiB / 301.87 KiB [---------------------------] 100.00% 2.07 MiB p/s 300ms\n"
     ]
    }
   ],
   "source": [
    "# Follow instructions here to first install the firectil CLI - https://readme.fireworks.ai/docs/fine-tuning-models#installing-firectl\n",
    "# Then run this command to upload the file to Fireworks\n",
    "!firectl create dataset {dataset_id} {dataset_file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fb601-ff13-40fb-967a-b8ebc098fd48",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n",
    "\n",
    "We will now fine-tune models using the Fireworks API. Fireworks implements the QLoRA algorithm through a simple interface. Training parameters can be set via the --settings-file argument. In this exercise, we will fine-tune two models:\n",
    "- The first model will use Fireworks default training parameters\n",
    "- The second model will increase the rank, learning rate, and epochs to make fine-tuning more aggressive\n",
    "\n",
    "See https://docs.fireworks.ai/fine-tuning/fine-tuning-models#starting-your-tuning-job for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8dd75b-d1d4-4e9c-be55-e7c7777cbb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accounts/jayozer-ce1cd6/fineTuningJobs/f0ddb99646244b33a86f9df7edc0faa5\n",
      "Display Name: pk-faq-v1\n",
      "Create Time: 2024-09-17 06:08:06\n",
      "State: CREATING\n",
      "Dataset: accounts/jayozer-ce1cd6/datasets/pk-faq-v1\n",
      "Datasets: []\n",
      "Status: OK\n",
      "Created By: jayozer@gmail.com\n",
      "Container Version: \n",
      "Model Id: \n",
      "Conversation:\n",
      "  Jinja Template: {%- set _mode = mode | default('generate', true) -%}\n",
      "{%- set stop_token = '<|eot_id|>' -%}\n",
      "{%- set message_roles = ['SYSTEM', 'USER', 'ASSISTANT'] -%}\n",
      "{%- set ns = namespace(initial_system_message_handled=false, last_assistant_index_for_eos=-1, messages=messages) -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if not message.get('role') -%}\n",
      "        {{ raise_exception('Key [role] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if message['role'] | upper not in message_roles -%}\n",
      "        {{ raise_exception('Invalid role ' + message['role']|tojson + '. Only ' + message_roles|tojson + ' are supported.') }}\n",
      "    {%- endif -%}\n",
      "    {%- if 'content' not in message -%}\n",
      "        {{ raise_exception('Key [content] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if loop.last and message['role'] | upper == 'ASSISTANT' -%}\n",
      "        {%- set ns.last_assistant_index_for_eos = loop.index0 -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' -%}\n",
      "    {{ bos_token }}\n",
      "{%- endif -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if message['role'] | upper == 'SYSTEM' and not ns.initial_system_message_handled -%}\n",
      "        {%- set ns.initial_system_message_handled = true -%}\n",
      "        {{ '<|start_header_id|>system<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "    {%- elif message['role'] | upper != 'SYSTEM' -%}\n",
      "        {%- if (message['role'] | upper == 'USER') != ((loop.index0 - (1 if ns.initial_system_message_handled else 0)) % 2 == 0) -%}\n",
      "            {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\n",
      "        {%- endif -%}\n",
      "        {%- if message['role'] | upper == 'USER' -%}\n",
      "            {{ '<|start_header_id|>user<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "        {%- elif message['role'] | upper == 'ASSISTANT' -%}\n",
      "            {%- if _mode == 'train' -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + unk_token + message['content'] + stop_token + unk_token }}\n",
      "            {%- else -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + message['content'] + (stop_token if loop.index0 != ns.last_assistant_index_for_eos else '') }}\n",
      "            {%- endif -%}\n",
      "        {%- endif -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' and ns.last_assistant_index_for_eos == -1 -%}\n",
      "    {{ '<|start_header_id|>assistant<|end_header_id|>' }}\n",
      "{%- endif -%}\n",
      "\n",
      "Base Model: accounts/fireworks/models/llama-v3-8b-instruct-hf\n",
      "Warm Start From: \n",
      "Epochs: 1\n",
      "Learning Rate: 0.0001\n",
      "Lora Rank: 8\n",
      "Batch Size: 16\n",
      "Micro Batch Size: 0\n",
      "Mask Token: \n",
      "Pad Token: \n",
      "Cutoff Length: 0\n",
      "Wandb Url: \n",
      "Wandb Entity: \n",
      "Wandb Api Key: \n",
      "Wandb Project: \n",
      "Evaluation: false\n",
      "Evaluation Split: 0\n",
      "Dependent Jobs: []\n"
     ]
    }
   ],
   "source": [
    "# Creates a training job with the default hyperparameters\n",
    "!firectl create fine-tuning-job --settings-file /Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk-faq-v1.yaml --display-name pk-faq-v1 --dataset {dataset_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d541454-c4b0-4a4c-b058-4cb19cb48542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accounts/jayozer-ce1cd6/fineTuningJobs/427f1b67937e40a5bb3ef06a0c3770d5\n",
      "Display Name: pk-faq-v2\n",
      "Create Time: 2024-09-17 06:08:29\n",
      "State: CREATING\n",
      "Dataset: accounts/jayozer-ce1cd6/datasets/pk-faq-v1\n",
      "Datasets: []\n",
      "Status: OK\n",
      "Created By: jayozer@gmail.com\n",
      "Container Version: \n",
      "Model Id: \n",
      "Conversation:\n",
      "  Jinja Template: {%- set _mode = mode | default('generate', true) -%}\n",
      "{%- set stop_token = '<|eot_id|>' -%}\n",
      "{%- set message_roles = ['SYSTEM', 'USER', 'ASSISTANT'] -%}\n",
      "{%- set ns = namespace(initial_system_message_handled=false, last_assistant_index_for_eos=-1, messages=messages) -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if not message.get('role') -%}\n",
      "        {{ raise_exception('Key [role] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if message['role'] | upper not in message_roles -%}\n",
      "        {{ raise_exception('Invalid role ' + message['role']|tojson + '. Only ' + message_roles|tojson + ' are supported.') }}\n",
      "    {%- endif -%}\n",
      "    {%- if 'content' not in message -%}\n",
      "        {{ raise_exception('Key [content] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if loop.last and message['role'] | upper == 'ASSISTANT' -%}\n",
      "        {%- set ns.last_assistant_index_for_eos = loop.index0 -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' -%}\n",
      "    {{ bos_token }}\n",
      "{%- endif -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if message['role'] | upper == 'SYSTEM' and not ns.initial_system_message_handled -%}\n",
      "        {%- set ns.initial_system_message_handled = true -%}\n",
      "        {{ '<|start_header_id|>system<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "    {%- elif message['role'] | upper != 'SYSTEM' -%}\n",
      "        {%- if (message['role'] | upper == 'USER') != ((loop.index0 - (1 if ns.initial_system_message_handled else 0)) % 2 == 0) -%}\n",
      "            {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\n",
      "        {%- endif -%}\n",
      "        {%- if message['role'] | upper == 'USER' -%}\n",
      "            {{ '<|start_header_id|>user<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "        {%- elif message['role'] | upper == 'ASSISTANT' -%}\n",
      "            {%- if _mode == 'train' -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + unk_token + message['content'] + stop_token + unk_token }}\n",
      "            {%- else -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + message['content'] + (stop_token if loop.index0 != ns.last_assistant_index_for_eos else '') }}\n",
      "            {%- endif -%}\n",
      "        {%- endif -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' and ns.last_assistant_index_for_eos == -1 -%}\n",
      "    {{ '<|start_header_id|>assistant<|end_header_id|>' }}\n",
      "{%- endif -%}\n",
      "\n",
      "Base Model: accounts/fireworks/models/llama-v3-8b-instruct-hf\n",
      "Warm Start From: \n",
      "Epochs: 2\n",
      "Learning Rate: 0.0002\n",
      "Lora Rank: 32\n",
      "Batch Size: 16\n",
      "Micro Batch Size: 0\n",
      "Mask Token: \n",
      "Pad Token: \n",
      "Cutoff Length: 0\n",
      "Wandb Url: \n",
      "Wandb Entity: \n",
      "Wandb Api Key: \n",
      "Wandb Project: \n",
      "Evaluation: false\n",
      "Evaluation Split: 0\n",
      "Dependent Jobs: []\n"
     ]
    }
   ],
   "source": [
    "# Creates a training job with the increased rank, learning rate, and epochs\n",
    "!firectl create fine-tuning-job --settings-file /Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/pk-faq-v2.yaml --display-name pk-faq-v2 --dataset {dataset_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8565ac9-eb20-4070-8c7c-7796d199f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 is the id of the training job with default hyperparameters, v2 is with the increased settings\n",
    "# NOTE THAT THESE IDS WILL CHANGE WHEN YOU RUN THE FINE-TUNING JOB ON YOUR ACCOUNT!!!\n",
    "# The model id is printed in the stdout of the cell above as Name: accounts/{account_id}/fineTuningJobs/{model_id}\n",
    "model_v1_id = 'f0ddb99646244b33a86f9df7edc0faa5'\n",
    "model_v2_id = '427f1b67937e40a5bb3ef06a0c3770d5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "498a82de-3e66-47ec-bab4-b951ef86c57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accounts/jayozer-ce1cd6/fineTuningJobs/f0ddb99646244b33a86f9df7edc0faa5\n",
      "Display Name: pk-faq-v1\n",
      "Create Time: 2024-09-17 06:08:06\n",
      "State: COMPLETED\n",
      "Dataset: accounts/jayozer-ce1cd6/datasets/pk-faq-v1\n",
      "Datasets: []\n",
      "Status:\n",
      "  Code: OK\n",
      "  Message: {'train_runtime': 56.6165, 'train_samples_per_second': 11.922, 'train_steps_per_second': 0.742, 'total_flos': 3057560957485056.0, 'train_loss': 1.6841438100451516, 'epoch': 0.9882352941176471}\n",
      "Created By: jayozer@gmail.com\n",
      "Container Version: \n",
      "Model Id: f0ddb99646244b33a86f9df7edc0faa5\n",
      "Conversation:\n",
      "  Jinja Template: {%- set _mode = mode | default('generate', true) -%}\n",
      "{%- set stop_token = '<|eot_id|>' -%}\n",
      "{%- set message_roles = ['SYSTEM', 'USER', 'ASSISTANT'] -%}\n",
      "{%- set ns = namespace(initial_system_message_handled=false, last_assistant_index_for_eos=-1, messages=messages) -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if not message.get('role') -%}\n",
      "        {{ raise_exception('Key [role] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if message['role'] | upper not in message_roles -%}\n",
      "        {{ raise_exception('Invalid role ' + message['role']|tojson + '. Only ' + message_roles|tojson + ' are supported.') }}\n",
      "    {%- endif -%}\n",
      "    {%- if 'content' not in message -%}\n",
      "        {{ raise_exception('Key [content] is missing. Original input: ' +  message|tojson) }}\n",
      "    {%- endif -%}\n",
      "    {%- if loop.last and message['role'] | upper == 'ASSISTANT' -%}\n",
      "        {%- set ns.last_assistant_index_for_eos = loop.index0 -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' -%}\n",
      "    {{ bos_token }}\n",
      "{%- endif -%}\n",
      "{%- for message in ns.messages -%}\n",
      "    {%- if message['role'] | upper == 'SYSTEM' and not ns.initial_system_message_handled -%}\n",
      "        {%- set ns.initial_system_message_handled = true -%}\n",
      "        {{ '<|start_header_id|>system<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "    {%- elif message['role'] | upper != 'SYSTEM' -%}\n",
      "        {%- if (message['role'] | upper == 'USER') != ((loop.index0 - (1 if ns.initial_system_message_handled else 0)) % 2 == 0) -%}\n",
      "            {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\n",
      "        {%- endif -%}\n",
      "        {%- if message['role'] | upper == 'USER' -%}\n",
      "            {{ '<|start_header_id|>user<|end_header_id|>\\n\\n' + message['content'] + stop_token }}\n",
      "        {%- elif message['role'] | upper == 'ASSISTANT' -%}\n",
      "            {%- if _mode == 'train' -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + unk_token + message['content'] + stop_token + unk_token }}\n",
      "            {%- else -%}\n",
      "                {{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' + message['content'] + (stop_token if loop.index0 != ns.last_assistant_index_for_eos else '') }}\n",
      "            {%- endif -%}\n",
      "        {%- endif -%}\n",
      "    {%- endif -%}\n",
      "{%- endfor -%}\n",
      "{%- if _mode == 'generate' and ns.last_assistant_index_for_eos == -1 -%}\n",
      "    {{ '<|start_header_id|>assistant<|end_header_id|>' }}\n",
      "{%- endif -%}\n",
      "\n",
      "Base Model: accounts/fireworks/models/llama-v3-8b-instruct-hf\n",
      "Warm Start From: \n",
      "Epochs: 1\n",
      "Learning Rate: 0.0001\n",
      "Lora Rank: 8\n",
      "Batch Size: 16\n",
      "Micro Batch Size: 0\n",
      "Mask Token: \n",
      "Pad Token: \n",
      "Cutoff Length: 0\n",
      "Wandb Url: \n",
      "Wandb Entity: \n",
      "Wandb Api Key: \n",
      "Wandb Project: \n",
      "Evaluation: false\n",
      "Evaluation Split: 0\n",
      "Dependent Jobs: []\n"
     ]
    }
   ],
   "source": [
    "# Wait until the State of the two fine-tuning jobs are listed as COMPLETED (~10-20 minutes)\n",
    "!firectl get fine-tuning-job {model_v1_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df2a33-7d60-4ee7-8b2c-7c1d08c90ce9",
   "metadata": {},
   "source": [
    "### Evluate Results\n",
    "\n",
    "We will now deploy our models and evaluate the results. We will calculate the accuracy on three different models\n",
    "\n",
    "- The base model without any fine-tuning\n",
    "- Our first fine-tuned model, with the default hyperparameters\n",
    "- Our second fine-tuned model, with the more aggressive hyperparameters\n",
    "\n",
    "See https://docs.fireworks.ai/fine-tuning/fine-tuning-models#deploying-the-model-for-inference for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6d45aab-a44f-4442-8e84-e14751b688d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the first model to a Fireworks serverless endpoint\n",
    "!firectl deploy {model_v1_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9580299-573a-4727-8f7b-3d0f068cebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the second model to a Fireworks serverless endpoint\n",
    "!firectl deploy {model_v2_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f081c2cc-d5a5-4763-8902-5833522c7fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accounts/jayozer-ce1cd6/models/f0ddb99646244b33a86f9df7edc0faa5\n",
      "Display Name: \n",
      "Description: \n",
      "Create Time: 2024-09-17 06:13:42\n",
      "Created By: \n",
      "State: READY\n",
      "Status: OK\n",
      "Kind: HF_PEFT_ADDON\n",
      "Github Url: \n",
      "Hugging Face Url: \n",
      "Base Model Details:\n",
      "  World Size: 0\n",
      "  Checkpoint Format: CHECKPOINT_FORMAT_UNSPECIFIED\n",
      "  Parameter Count: 0\n",
      "  Moe: false\n",
      "Peft Details:\n",
      "  Base Model: accounts/fireworks/models/llama-v3-8b-instruct-hf\n",
      "  R: 8\n",
      "  Target Modules: [q_proj, v_proj, gate_proj, o_proj, k_proj, down_proj, up_proj]\n",
      "Public: false\n",
      "Conversation Config:\n",
      "  Style: jinja\n",
      "  System: \n",
      "  Template: \n",
      "Context Length: 8192\n",
      "Supports Image Input: false\n",
      "Supports Tools: false\n",
      "Imported From: \n",
      "Fine Tuning Job: accounts/jayozer-ce1cd6/fineTuningJobs/f0ddb99646244b33a86f9df7edc0faa5\n",
      "Default Draft Model: \n",
      "Default Draft Token Count: 0\n",
      "Precisions: []\n",
      "Deployed Model Refs: \n",
      "  [{\n",
      "    Name: accounts/jayozer-ce1cd6/deployedModels/f0ddb99646244b33a86f9df7edc0faa5-d6de0bd7\n",
      "    Deployment: accounts/fireworks/deployments/21c38bed\n",
      "    State: DEPLOYED\n",
      "    Default: true\n",
      "  }]\n",
      "Cluster: \n"
     ]
    }
   ],
   "source": [
    "# Wait until the the Deploymed Model Refs lists the state of the models as \"DEPLOYED\" (~5-20 minutes).\n",
    "!firectl get model {model_v1_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18b074e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fireworks.client import Fireworks\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variable\n",
    "api_key = os.getenv('FIREWORKS_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cd2ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accounts/fireworks/models/llama-v3-8b-instruct\n",
      "Display Name: Llama 3 8B Instruct\n",
      "Description: Meta developed and released the Meta Llama 3 family of large language models (LLMs), a collection of pretrained and instruction tuned generative text models in 8 and 70B sizes. The Llama 3 instruction tuned models are optimized for dialogue use cases and outperform many of the available open source chat models on common industry benchmarks.\n",
      "Create Time: 2024-04-18 13:29:41\n",
      "Created By: yingliu@fireworks.ai\n",
      "State: READY\n",
      "Status: OK\n",
      "Kind: HF_BASE_MODEL\n",
      "Github Url: https://github.com/meta-llama/llama3\n",
      "Hugging Face Url: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Base Model Details:\n",
      "  World Size: 1\n",
      "  Checkpoint Format: NATIVE\n",
      "  Parameter Count: 0\n",
      "  Moe: false\n",
      "Public: true\n",
      "Conversation Config:\n",
      "  Style: jinja\n",
      "  System: \n",
      "  Template: \n",
      "Context Length: 8192\n",
      "Supports Image Input: false\n",
      "Supports Tools: false\n",
      "Imported From: \n",
      "Fine Tuning Job: \n",
      "Default Draft Model: \n",
      "Default Draft Token Count: 0\n",
      "Precisions: []\n",
      "Deployed Model Refs: \n",
      "  [{\n",
      "    Name: accounts/fireworks/deployedModels/llama-v3-8b-instruct-0b565868\n",
      "    Deployment: accounts/fireworks/deployments/ced3d1f0\n",
      "    State: DEPLOYED\n",
      "    Default: true\n",
      "  }]\n",
      "Cluster: \n"
     ]
    }
   ],
   "source": [
    "! firectl get model accounts/fireworks/models/llama-v3-8b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1934c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have access to the model.\n",
      "Model response: Hello there! Nice to meet you! Is there\n"
     ]
    }
   ],
   "source": [
    "from fireworks.client import Fireworks\n",
    "import os\n",
    "\n",
    "# Make sure you have the FIREWORKS_API_KEY environment variable set\n",
    "api_key = os.getenv('FIREWORKS_API_KEY')\n",
    "\n",
    "client = Fireworks(api_key=api_key)\n",
    "\n",
    "model_id = 'accounts/fireworks/models/llama-v3-8b-instruct'\n",
    "\n",
    "try:\n",
    "    # Attempt to create a chat completion with the model\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hello, world!\"}\n",
    "        ],\n",
    "        max_tokens=10\n",
    "    )\n",
    "    print(\"You have access to the model.\")\n",
    "    print(\"Model response:\", response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(\"You might not have access to this model.\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e18e6cb6-cf83-4393-a804-a13360794b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Base Model...\n",
      "Training Set Accuracy: 0.0%\n",
      "Test Set Accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "def get_model_response(question, model):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are Poppy, a helpful assistant for Poppy Kids Pediatric Dentistry.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=2048,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def evaluate_accuracy(predicted_answers, actual_answers):\n",
    "    correct = sum(1 for pred, actual in zip(predicted_answers, actual_answers) if pred.lower() == actual.lower())\n",
    "    return round(100 * correct / len(actual_answers), 2)\n",
    "\n",
    "# Load your train and test data\n",
    "train_data = pd.read_csv('/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/train.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/test.tsv', sep='\\t')\n",
    "\n",
    "# Base model ID\n",
    "base_model_id = 'accounts/fireworks/models/llama-v3-8b-instruct'\n",
    "\n",
    "print(\"Evaluating Base Model...\")\n",
    "\n",
    "# Evaluate on training set\n",
    "train_responses = [get_model_response(question, base_model_id) for question in train_data['question']]\n",
    "train_accuracy = evaluate_accuracy(train_responses, train_data['answer'])\n",
    "print(f\"Training Set Accuracy: {train_accuracy}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_responses = [get_model_response(question, base_model_id) for question in test_data['question']]\n",
    "test_accuracy = evaluate_accuracy(test_responses, test_data['answer'])\n",
    "print(f\"Test Set Accuracy: {test_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2200252",
   "metadata": {},
   "source": [
    "# Check Finetune model v1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66b07765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: accounts/jayozer-ce1cd6/models/f0ddb99646244b33a86f9df7edc0faa5\n"
     ]
    }
   ],
   "source": [
    "# Determine how the fine-tuned model performs with the default fine-tuning params\n",
    "model_id = f'accounts/{account_id}/models/{model_v1_id}'\n",
    "print(f\"Model ID: {model_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_response(question, model):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are Poppy, a helpful assistant for Poppy Kids Pediatric Dentistry.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=2048,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def evaluate_accuracy(predicted_answers, actual_answers):\n",
    "    correct = sum(1 for pred, actual in zip(predicted_answers, actual_answers) if pred.lower() == actual.lower())\n",
    "    return round(100 * correct / len(actual_answers), 2)\n",
    "\n",
    "# Load your train and test data\n",
    "train_data = pd.read_csv('/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/train.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('/Users/acrobat/Documents/GitHub/fine-tuning-workshop/poppykids/pk_data/test.tsv', sep='\\t')\n",
    "\n",
    "# Your fine-tuned model ID\n",
    "account_id = os.getenv('FIREWORKS_ACCOUNT_ID')  # Make sure this environment variable is set\n",
    "fine_tuned_model_id = 'f0ddb99646244b33a86f9df7edc0faa5'  # Replace with your actual fine-tuned model ID\n",
    "full_fine_tuned_model_id = f'accounts/{account_id}/models/{fine_tuned_model_id}'\n",
    "\n",
    "print(\"Evaluating Fine-tuned Model...\")\n",
    "\n",
    "# Evaluate on training set\n",
    "train_responses = [get_model_response(question, full_fine_tuned_model_id) for question in train_data['question']]\n",
    "train_accuracy = evaluate_accuracy(train_responses, train_data['answer'])\n",
    "print(f\"Training Set Accuracy: {train_accuracy}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_responses = [get_model_response(question, full_fine_tuned_model_id) for question in test_data['question']]\n",
    "test_accuracy = evaluate_accuracy(test_responses, test_data['answer'])\n",
    "print(f\"Test Set Accuracy: {test_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "256d7c65-4050-43e0-881d-58a1ad398de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 69.12%\n",
      "Test Set Accuracy: 67.65%\n"
     ]
    }
   ],
   "source": [
    "# Determine how the fine-tuned model performs with the default fine-tuning params\n",
    "model_id = f'accounts/{account_id}/models/{model_v1_id}'\n",
    "\n",
    "training_responses = classify_tickets(\n",
    "    tickets=training_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "accuracy = evaluate_accuracy(training_responses, training_labels)\n",
    "print(f\"Training Set Accuracy: {accuracy}%\")\n",
    "\n",
    "test_responses = classify_tickets(\n",
    "    tickets=test_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "\n",
    "accuracy = evaluate_accuracy(test_responses, test_labels)\n",
    "print(f\"Test Set Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "198b6a3a-422e-4157-b5b2-b00f9ddcb106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 61.76%\n",
      "Test Set Accuracy: 55.88%\n"
     ]
    }
   ],
   "source": [
    "# Determine how the base model performs with the increases rank, epochs, and learning rate\n",
    "model_id = f'accounts/{account_id}/models/{model_v2_id}'\n",
    "\n",
    "training_responses = classify_tickets(\n",
    "    tickets=training_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "accuracy = evaluate_accuracy(training_responses, training_labels)\n",
    "print(f\"Training Set Accuracy: {accuracy}%\")\n",
    "\n",
    "test_responses = classify_tickets(\n",
    "    tickets=test_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "\n",
    "accuracy = evaluate_accuracy(test_responses, test_labels)\n",
    "print(f\"Test Set Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86c759ab-f84e-44bb-b621-86550519c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undeploy the first model (does not cost anything extra, but Fireworks may limit your number of deployed models).\n",
    "!firectl undeploy {model_v1_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b09d5f87-0bcb-4078-a6ff-2a02c8ccc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undeploy the second model (does not cost anything extra, but Fireworks may limit your number of deployed models).\n",
    "!firectl undeploy {model_v2_id}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
